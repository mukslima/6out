{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukslima/6out/blob/main/Exercicios_Revisao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "## Exercício 1 - Dataset Digits do sklearn\n",
        "\n",
        "# Acesso: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits\n",
        "\n",
        "# 1) Importar o pacote \"sklearn.datasets\" e o \"load_digits\"\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "# 2) Carregar o dataset através do método: load_digits()\n",
        "digits = load_digits()\n",
        "\n",
        "# 3) Observe as keys do dataset usando o método \"keys\"\n",
        "print(digits.keys())\n",
        "\n",
        "# 4) A chave \"data\" são as features e a chave \"target\" é o y. Separe os dados em 2 variáveis diferentes\n",
        "x = digits.data\n",
        "y = digits.target\n",
        "\n",
        "# 5) Verificar a dimensionalidade das features através da variável shape\n",
        "print(x.shape)\n",
        "\n",
        "# 6) Executar os experimentos 10x usando validação cruzada e mostrar a média das 10 execuções para cada algoritmo de aprendizado\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "  #> 7) Separe o conjunto de dados em treinamento e teste usando o método: \"train_test_split\"\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "  #> 8) Treinar MLP\n",
        "mlp = MLPClassifier(max_iter=300, random_state=42)\n",
        "mlp_scores = cross_val_score(mlp, X_train, y_train, cv=10)\n",
        "print(f\"MLP Mean Accuracy: {mlp_scores.mean()}\")\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "print(f\"MLP Test Accuracy: {accuracy_score(y_test, y_pred_mlp)}\")\n",
        "\n",
        "  #> 9 Treinar Árvore de Decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree_scores = cross_val_score(tree, X_train, y_train, cv=10)\n",
        "print(f\"Decision Tree Mean Accuracy: {tree_scores.mean()}\")\n",
        "tree.fit(X_train, y_train)\n",
        "y_pred_tree = tree.predict(X_test)\n",
        "print(f\"Decision Tree Test Accuracy: {accuracy_score(y_test, y_pred_tree)}\")\n",
        "\n",
        "  #> 10) Treinar KNN\n",
        "knn = KNeighborsClassifier()\n",
        "knn_scores = cross_val_score(knn, X_train, y_train, cv=10)\n",
        "print(f\"KNN Mean Accuracy: {knn_scores.mean()}\")\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "print(f\"KNN Test Accuracy: {accuracy_score(y_test, y_pred_knn)}\")\n",
        "\n",
        "  #> 11) Treinar K-Means\n",
        "\n",
        "    #>> 12) No K-Means, treine com 10 clusters (a base load_digits tem 10 classes)\n",
        "kmeans = KMeans(n_clusters=10, random_state=42, n_init = 'auto')\n",
        "kmeans.fit(X_train)\n",
        "y_kmeans_train = kmeans.predict(X_train)\n",
        "y_kmeans_test = kmeans.predict(X_test)\n",
        "\n",
        "    #>> 13) Fazer o mapeamento dos clusters com as classes, conforme o código que tá no classroom\n",
        "from scipy.stats import mode\n",
        "labels = np.zeros_like(y_kmeans_train)\n",
        "for i in range(10):\n",
        "    mask = (y_kmeans_train == i)\n",
        "    labels[mask] = mode(y_train[mask])[0]\n",
        "\n",
        "y_pred_kmeans = labels[y_kmeans_test]\n",
        "\n",
        "print(f\"K-Means Test Accuracy: {accuracy_score(y_test, y_pred_kmeans)}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpS4vVvq0Pxt",
        "outputId": "daefbc30-c84c-4210-9a7e-2f745b06b76d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
            "(1797, 64)\n",
            "MLP Mean Accuracy: 0.9742521367521368\n",
            "MLP Test Accuracy: 0.9833333333333333\n",
            "Decision Tree Mean Accuracy: 0.8524912587412586\n",
            "Decision Tree Test Accuracy: 0.8416666666666667\n",
            "KNN Mean Accuracy: 0.9860819735819735\n",
            "KNN Test Accuracy: 0.9861111111111112\n",
            "K-Means Test Accuracy: 0.044444444444444446\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# %%\n",
        "## Exercício 2 - Dataset Orange Juice\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "\n",
        "# 1) Carregar o dataset através do url abaixo:\n",
        "url = \"https://raw.githubusercontent.com/intro-stat-learning/ISLP/main/ISLP/data/OJ.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 3) O target é a coluna: \"Purchase\", ela é categórica e deve virar numérica via LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['Purchase'] = label_encoder.fit_transform(df['Purchase'])\n",
        "\n",
        "# Separar features e target\n",
        "X = df.drop('Purchase', axis=1)\n",
        "y = df['Purchase']\n",
        "\n",
        "  #> 6) Separe o conjunto de dados em treinamento e teste usando o método: \"train_test_split\"\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2) Fazer o One-Hot Encoder na coluna: \"Store7\" AFTER the train test split\n",
        "X_train = pd.get_dummies(X_train, columns=['Store7'])\n",
        "X_test = pd.get_dummies(X_test, columns=['Store7'])\n",
        "\n",
        "# 4) Normalizar todas as features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(X_train_scaled)\n",
        "print(X_test_scaled)\n",
        "\n",
        "  #> 7) Treinar MLP\n",
        "mlp = MLPClassifier(max_iter=300, random_state=42)\n",
        "mlp_scores = cross_val_score(mlp, X_train_scaled, y_train, cv=10)\n",
        "print(f\"MLP Mean Accuracy: {mlp_scores.mean()}\")\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "y_pred_mlp = mlp.predict(X_test_scaled)\n",
        "print(f\"MLP Test Accuracy: {accuracy_score(y_test, y_pred_mlp)}\")\n",
        "\n",
        "  #> 8 Treinar Árvore de Decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree_scores = cross_val_score(tree, X_train_scaled, y_train, cv=10)\n",
        "print(f\"Decision Tree Mean Accuracy: {tree_scores.mean()}\")\n",
        "tree.fit(X_train_scaled, y_train)\n",
        "y_pred_tree = tree.predict(X_test_scaled)\n",
        "print(f\"Decision Tree Test Accuracy: {accuracy_score(y_test, y_pred_tree)}\")\n",
        "\n",
        "  #> 9) Treinar KNN\n",
        "knn = KNeighborsClassifier()\n",
        "knn_scores = cross_val_score(knn, X_train_scaled, y_train, cv=10)\n",
        "print(f\"KNN Mean Accuracy: {knn_scores.mean()}\")\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "y_pred_knn = knn.predict(X_test_scaled)\n",
        "print(f\"KNN Test Accuracy: {accuracy_score(y_test, y_pred_knn)}\")\n",
        "\n",
        "  #> 10) Treinar K-Means\n",
        "kmeans = KMeans(n_clusters=2, random_state=42, n_init = 'auto')\n",
        "kmeans.fit(X_train_scaled)\n",
        "y_kmeans_train = kmeans.predict(X_train_scaled)\n",
        "y_kmeans_test = kmeans.predict(X_test_scaled)\n",
        "\n",
        "    #>> 11) No K-Means, treine com 2 clusters (a base tem 2 classes)\n",
        "from scipy.stats import mode\n",
        "labels = np.zeros_like(y_kmeans_train)\n",
        "for i in range(2):\n",
        "    mask = (y_kmeans_train == i)\n",
        "    labels[mask] = mode(y_train[mask])[0]\n",
        "\n",
        "y_pred_kmeans = labels[y_kmeans_test]\n",
        "\n",
        "print(f\"K-Means Test Accuracy: {accuracy_score(y_test, y_pred_kmeans)}\")\n",
        "\n",
        "  #>> 12) Fazer o mapeamento dos clusters com as classes, conforme o código que tá no classroom"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocVjWH7W2QI8",
        "outputId": "693961a9-76b9-4e5b-f735-5cd4d1d2d00f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.51185623  1.31550595  1.87366165 ... -1.13870987 -1.41545356\n",
            "   1.41545356]\n",
            " [-1.16529765 -0.85085244 -1.13108154 ...  0.25576173  0.70648733\n",
            "  -0.70648733]\n",
            " [ 0.30076281  1.31550595 -0.06488234 ... -1.13870987 -1.41545356\n",
            "   1.41545356]\n",
            " ...\n",
            " [ 0.42824633 -1.28412412 -1.03415434 ... -0.44147407  0.70648733\n",
            "  -0.70648733]\n",
            " [-0.84658885 -1.28412412 -0.06488234 ... -0.44147407  0.70648733\n",
            "  -0.70648733]\n",
            " [ 1.25688919  1.31550595 -0.06488234 ... -1.13870987 -1.41545356\n",
            "   1.41545356]]\n",
            "[[-0.97407237 -0.41758077 -0.74337274 ...  0.95299753  0.70648733\n",
            "  -0.70648733]\n",
            " [ 0.36450457 -0.85085244 -0.06488234 ...  0.25576173  0.70648733\n",
            "  -0.70648733]\n",
            " [ 1.25688919  0.01569091  1.19517125 ...  1.65023333  0.70648733\n",
            "  -0.70648733]\n",
            " ...\n",
            " [ 1.32063095 -0.85085244  0.90438965 ...  0.25576173  0.70648733\n",
            "  -0.70648733]\n",
            " [ 1.32063095 -0.85085244  0.90438965 ...  0.25576173  0.70648733\n",
            "  -0.70648733]\n",
            " [ 0.36450457 -0.85085244 -0.06488234 ...  0.25576173  0.70648733\n",
            "  -0.70648733]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Mean Accuracy: 0.8212995896032831\n",
            "MLP Test Accuracy: 0.8177570093457944\n",
            "Decision Tree Mean Accuracy: 0.7652120383036936\n",
            "Decision Tree Test Accuracy: 0.6682242990654206\n",
            "KNN Mean Accuracy: 0.7863337893296853\n",
            "KNN Test Accuracy: 0.7570093457943925\n",
            "K-Means Test Accuracy: 0.6074766355140186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}