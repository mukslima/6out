{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukslima/6out/blob/main/12_exerc%C3%ADcios_MLP_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UiwNFZi0EwsL",
        "outputId": "271e4994-0cbb-4c13-bdf2-d13848e1d322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
            "(1797, 64)\n"
          ]
        }
      ],
      "source": [
        "## Exercício 1 - Dataset Digits do sklearn\n",
        "\n",
        "# Acesso: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits\n",
        "\n",
        "# 1) Importar o pacote \"sklearn.datasets\" e o \"load_digits\"\n",
        "import sklearn.datasets\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "# 2) Carregar o dataset através do método: load_digits()\n",
        "digits = load_digits()\n",
        "\n",
        "# 3) Observe as keys do dataset usando o método \"keys\"\n",
        "print(digits.keys())\n",
        "\n",
        "# 4) A chave \"data\" são as features e a chave \"target\" é o y. Separe os dados em 2 variáveis diferentes\n",
        "x = digits.data\n",
        "y = digits.target\n",
        "\n",
        "# 5) Verificar a dimensionalidade das features através da variável shape\n",
        "print(digits.data.shape)\n",
        "\n",
        "# 6) Separe o conjunto de dados em treinamento e teste usando o método: \"train_test_split\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_x, test_x, train_y, test_y = train_test_split(digits.data, digits.target, test_size=0.2)\n",
        "\n",
        "# 7) Treinar MLP (2 topologias diferentes)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# 8) Treinar Árvore de Decisão (com Entropia e Gini)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 9) Treinar Árvore de Decisão com max_depth = 2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# 10) Treinar KNN (com duas características diferentes)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 11) Mostrar a taxa de acerto de todos os modelos\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Exercício 2 - Dataset Diabetes do sklearn (Base de Dados de Regressão)\n",
        "\n",
        "# Acesso: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes\n",
        "\n",
        "# 1) Importar o pacote \"sklearn.datasets\" e o \"load_diabetes\"\n",
        "import sklearn.datasets\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "# 2) Carregar o dataset através do método: load_diabetes()\n",
        "diabetes = load_diabetes()\n",
        "\n",
        "# 3) Observe as keys do dataset usando o método \"keys\"\n",
        "print(diabetes.keys())\n",
        "\n",
        "# 4) A chave \"data\" são as features e a chave \"target\" é o y. Separe os dados em 2 variáveis diferentes\n",
        "x = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "# 5) Verificar a dimensionalidade das features através da variável shape\n",
        "print(diabetes.data.shape)\n",
        "\n",
        "# 6) Separe o conjunto de dados em treinamento e teste usando o método: \"train_test_split\"\n",
        "train_x, test_x, train_y, test_y = train_test_split(diabetes.data, diabetes.target, test_size=0.2)\n",
        "\n",
        "# 7) Treinar MLP (2 topologias diferentes) - MLPRegressor()\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mlp1 = MLPRegressor(hidden_layer_sizes=(10,), activation='relu', solver='adam', random_state=42)\n",
        "mlp2 = MLPRegressor(hidden_layer_sizes=(20, 10), activation='relu', solver='adam', random_state=42)\n",
        "\n",
        "mlp1.fit(train_x, train_y)\n",
        "mlp2.fit(train_x, train_y)\n",
        "\n",
        "predictions_mlp1 = mlp1.predict(test_x)\n",
        "predictions_mlp2 = mlp2.predict(test_x)\n",
        "\n",
        "mse_mlp1 = mean_squared_error(test_y, predictions_mlp1)\n",
        "mse_mlp2 = mean_squared_error(test_y, predictions_mlp2)\n",
        "\n",
        "print(\"MSE MLP1: %.2f\" % mse_mlp1)\n",
        "print(\"MSE MLP2: %.2f\" % mse_mlp2)\n",
        "\n",
        "# 8) Treinar Árvore de Decisão - DecisionTreeRegressor()\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "tree = DecisionTreeRegressor(random_state=42)\n",
        "tree.fit(train_x, train_y)\n",
        "predictions_tree = tree.predict(test_x)\n",
        "mse_tree = mean_squared_error(test_y, predictions_tree)\n",
        "\n",
        "print(\"MSE Decision Tree: %.2f\" % mse_tree)\n",
        "\n",
        "# 9) Treinar Árvore de Decisão com max_depth = 2 - DecisionTreeRegressor()\n",
        "tree_depth2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_depth2.fit(train_x, train_y)\n",
        "predictions_tree_depth2 = tree_depth2.predict(test_x)\n",
        "mse_tree_depth2 = mean_squared_error(test_y, predictions_tree_depth2)\n",
        "\n",
        "print(\"MSE Decision Tree (max_depth=2): %.2f\" % mse_tree_depth2)\n",
        "\n",
        "# 10) Treinar KNN (com duas características diferentes) - KNeighborsRegressor()\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "knn1 = KNeighborsRegressor(n_neighbors=5)\n",
        "knn2 = KNeighborsRegressor(n_neighbors=10)\n",
        "knn1.fit(train_x, train_y)\n",
        "knn2.fit(train_x, train_y)\n",
        "predictions_knn1 = knn1.predict(test_x)\n",
        "predictions_knn2 = knn2.predict(test_x)\n",
        "mse_knn1 = mean_squared_error(test_y, predictions_knn1)\n",
        "mse_knn2 = mean_squared_error(test_y, predictions_knn2)\n",
        "\n",
        "print(\"MSE KNN (n_neighbors=5): %.2f\" % mse_knn1)\n",
        "print(\"MSE KNN (n_neighbors=10): %.2f\" % mse_knn2)\n",
        "\n",
        "# 11) Treinar o modelo de Regressão Linear - LinearRegression()\n",
        "from sklearn.linear_model import LinearRegression\n",
        "linear_reg = LinearRegression()\n",
        "linear_reg.fit(train_x, train_y)\n",
        "predictions_linear_reg = linear_reg.predict(test_x)\n",
        "\n",
        "# 12) Usar o MSE (Mean Squared Error) pra avaliar os modelos:\n",
        "mse_linear_reg = mean_squared_error(test_y, predictions_linear_reg)\n",
        "\n",
        "print(\"MSE Linear Regression: %.2f\" % mse_linear_reg)\n",
        "\n",
        "# Exemplo: print(\"MSE: %.2f\" % mean_squared_error(teste_y, prediction))"
      ],
      "metadata": {
        "id": "_362ExMzHvvB",
        "outputId": "9e4c1b2a-6a84-42ff-c539-66670712925e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])\n",
            "(442, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE MLP1: 31538.33\n",
            "MSE MLP2: 25473.79\n",
            "MSE Decision Tree: 8781.99\n",
            "MSE Decision Tree (max_depth=2): 4802.60\n",
            "MSE KNN (n_neighbors=5): 5004.94\n",
            "MSE KNN (n_neighbors=10): 4386.94\n",
            "MSE Linear Regression: 3310.22\n"
          ]
        }
      ]
    }
  ]
}